# R语言入门与数据分析-----------------------------------------------------------
# Creator: Fan-Yingfei
# Create based on the note by Fangyi Li
# 本笔记基于哔哩哔哩弹幕网视频：R语言入门与数据分析（up主id：基因学院）总结而成。
# This note is created based on a video, Introduction to R programming language 
# and data analysis, on the website of Bilibili (id: 基因学院).

# P1-6    Introduction of R-----------------------------------------------------

# 数据采集 -> 数据挖掘（Data mining）
#   - 三个特点
#     - 数据整体性
#     - 不追求精确性
#     - 因果关系（x）
#     - 相关性（√）
#   - 通过算法发现新东西（规律）-> 相同数据不同结果 -> 结果可视化（数据去抽象化） 
#     -> 决策

# R语言特点
#   - 编程开源（大量拓展包）
#   - 绘图功能
#   - 面向对象
#   - 不够规范、不支持多线程
#   - 函数后必须接括号

getwd()
# 看路径
setwd()
# 修改路径
getwd()
setwd("/Users/nan-fan/Desktop/R软件学习/RData/")


df <- read.table("dataname.cvs", sep=",", header = T)
# df将数据文件命名
# read.table()读写Excel数据文件
# sep=","来表示空格用字符

table(df$supp, df$dose)
# table()用于制作新表格，$用于统计总量
# aggregate()测量均值、方差等

 

# P7-14   R的安装--------------------------------------------------------------

# - 用 "<-" 赋值给一个局部变量
# - 用 "<<-" 赋值给一个全局变量
# - "<-"的快捷键：alt + - 

# 选项tools-global option
# 设置studio的界面等
# esc键可以中断当前操作

mean()
# mean(1:5) -> 3 求1-5的平均数
# mean(1,2,3,4,5) -> 1 只输出第一个向量（1）的平均数，后面为无效输入
# mean(c(1,2,3,4,5)) -> 3 增加的c()帮助识别一串数字

ls()
# 列出所有变量

ls.str()
# 列出所有变量的详细信息

str()
# 括号里填写变量名，输出变量的信息

rm()
# 清除某个变量
# 清除之后是无法恢复的

rm(y,z)
# 可以删除从y到z多个变量

list = ls()
# 让ls的值复制给list

rm(list = ls())
# 消除所有变量

history()
# 唤出历史
# 可以利用方向键上下来搜寻历史命令，然后可以用方向键左右键来更改

history(25)
# 可以给history()列出一个参数，表示只列出最近的25条参数

Ctrl + L
# 清空屏幕

save.image()
# 保存工作空间（图片不会自动保存）

q()
# 退出R

# R拓展包安装
# - 在线
#   通过访问镜像站点
#   拓展包的名字都需要被引号
install.package()
# eg. install.package("vcd")
install.packages()
# eg. install.packages(c("a", "b", "c"))
# - 离线（源代码）
#   镜像站点下载源代码
#   需要注意包之间的依赖关系
# 如果原镜像站点不可用，则需要修改站点。R-profile.set文件
# 使用.libPaths()能够显示库所在的位置

library()
# 可以显示库里有哪些安装包

library(vcd)
# 载入需要的R包，不需要添加""

require()
# 加载包（eg. require(vcd)）

help(package="") # eg. help(package="vcd")
# 查看包中内容和实例，

ls("package:") # eg. ls("package:vcd)
# 列出R包中所有包含的函数
 
data(package="") # eg. data(package="vcd")
# 列出R包中所有包含的数据集

detach() # eg. detach("package:vcd")，可用require()重新加载
remove.packages() # eg. remove.packages("vcd")，删除之后则无法再使用
# 去除包

installed.packages()
# 可用于拓展包移植，比如：
# 列出当前环境中已列出的R包

# 老设备
Rpack <- installed.packages() [,1] # Rpack赋值所有拓展包的名字
save(Rpack, file = "Rpack.Rdata") # 保存文件

# 新设备 
for (i in Rpact) install.packages(i)
# for 循环语句

# 查看帮助文档
# 软件-Help-R help
# help.start()
# help() # help(sum)
# ?函数名（一个问号查函数）eg. ?mean
# args() # args(plot)，直接输出plot函数需要的参数，而不会直接打开函数的详细信息
# example() # eg. example(mean)，给出函数实例
# help(package=) # eg.help(package=ggplot2)，查看某个包的帮助文档
# ??函数名（两个问号查拓展包）eg. ??heatmap
# help.search("") eg.help.search("heatmap")，在本地搜索

demo(graphics)
# 查看图形实例

apropos(关键字)
# 查询括号内的关键字
# eg. apropos("sum", mod="function")，只列出与sum有关的函数

RSiteSearch("关键字")
# 在R网址查询关键字 rseek.org

# R -> 大数据 -> 批量化、自动化
# Excel -> 鼠标操作方便



# P15     R内置数据集-----------------------------------------------------------

# - 存在datasets包中
# - data()输出所有包含的数据集 或 data(package = "包名")
# - 如果数据里面的某个变量被重新赋值，可以使用data("变量名")来赋值回数据集里的值

help(package="datasets")
# R中数据存于datasets包中

data()
# R中已有数据集


# 向量 -> 名称
# 因子 -> 分类
# 矩阵、数组 -> 不同东西的不同类型
# 类矩阵、数据框

data.frame()
# 制作数据框

data(数据集名称, package = "包名") 
# 只加载拓展包里面的数据集，忽略包

data(package=.packages(all.available = TRUE))
# 显示R内所有可用数据集


# P16-26  数据结构（R储存组织数据的方式）---------------------------------------

# - 数值型，数值可以用于直接计算，加减乘除
# - 字符串型，可以进行连接，转换，提取等
# - 逻辑型，真或者假
# - 日期型  

#             1. 向量（vector）-------------------------------------------------


# - 用函数c()来创建向量（数组）
# - - c()括号中可以加数值型变量，eg. x <- c(1, 2, 3, 4, 5)
# - - c()括号中可以加字符型变量，eg. y <- c("one","two","three")
# - 逻辑型向量：TRUE(T) OR FALSE(F)
# - 输出等差数列
seq(from = 起始数, to = 结尾数, by = 间隔, length.out = 输出数量)
# - 重复输出
rep(数组, 次数)
rep(数组, each=单个数字重复次数, times=将整体元素重复次数)
# - 一个数组里面的向量必须是同一类型，比如数值型和字符串不能混合
# > a <- c(1, 2, "three")
# > a 
#   "1" "2" "three" # 导致前面的数字向量全部变成字符串
# - 输出变量,向量化编程
# > a=2
# > b="Hello,World"
# > a;b
#   2
#   "Hello,World"
# - 向量化编程可以省略循环，比如：
# > x <- c(1, 2, 3, 4, 5)
# > y <- c(6, 7, 8, 9, 10)
# > x * 2 + y
#   8 11 14 17 20
# > x[x>3]  # 列出x中大于3的数
# - 使用c()来控制循环的次数
# > x <- c(1, 2, 3, 4, 5)
# > rep(x, c(2, 4, 1, 1, 3))
#   1 1 2 2 2 2 3 4 5 5 5

# - 向量索引
# 数值型向量
x <- c(1:100) # 对x赋值1-100，x为数组
length(数组) # 数组中元素数量
数组[位置] # 输出数组某个元素，eg. x[1] # x中第1个元素
数组[-位置] # 输出除了选中位置其余的所有元素
数组[c(位置,位置,位置)] # 输出数组中对应位置的元素，位置不能正负同时
数组[c(T,F,T,F)] # 利用逻辑向量T,F，相当于利用if循环语句循环执行
数组[数组>数值 & 数组<数值] # eg. y[y>5 & y<9]
# 字符串向量
z <- c("one","two","three","four","five")
"one" %in% z # %in%表示元素是否在向量中
z["one" %in% z] # 将逻辑条件添加到索引中
z[z %in% c("one","two")]
# > z %in% c("one","two")
#   TRUE  TRUE FALSE FALSE FALSE
# > k <- z %in% c("one","two")
# > z[k]
#   "one","two"
# 给向量添加名称
names(y) <- c("one","two","three","four","five","six","seven","eight","nine","ten")
数组["列名称"] # eg. y["one"] # 通过每一列的名称（表头）来访问列数据

# 添加或删除向量
x[101] <- 101 # 对x第101位赋值101
v <- 1:3 # 先对v进行赋值
v[c(4,5,6) <- c(4,5,6)] # 对v批量赋值
append(x = v, values = 99,after = 5) #在v的第5个元素之后添加元素99
append(x = v, values = 99,after = 0) #在v的头部添加元素99
rm(数组) # eg. rm(v) # 删除数组v
# 删除向量中某个元素
y[-c(1:3)] # 先找出y中剔除后的向量
y <- y[-c(1:3)] # 再用原来的向量名称替换剔除后的向量
# 修改向量中元素
y["four"] <- 100 # 将修改后的值赋给对应名称
v[2] <- 15 # 将修改后的值赋给对应位置，不可赋字符串
append() # 使用append不会mutate用来的向量

# - 向量运算
x + 1 # 向量与数的运算
y <- seq(1,100,length.out = 10) # 表示按顺序1-100，每间隔10个数出现一次
x * y # x·y
x ** y # x^y
x %% y # x/y的余数
x %/% y # x/y的整数部分（整除）
# 循环：
# 向量个数不同也可能可以相加，但长的向量个数必须是短的向量个数的整除数。
# 想要对比两个对象是否相等，应用两个等号==（一个等号相当于赋值）
# 可返回逻辑值
# > x > 2
#   FALSE FALSE TRUE TRUE

# 数学函数
abs() # 绝对值
sqrt() # 平方根
log(向量, base = log的底数) # 不加base默认底数是e
log10() # base是10的log
exp() # 以e为底的指数
ceiling() # 向上取整
floor() # 向下取整
trunc() # 向量内取整

# 四舍五入
round(向量, digits = 保留小数点位数)
signif(向量, digits = 总保留位数)

# 三角函数
sin()
cos()
tan()

# 统计函数
sum() # 求和
max() # 最大值
min() # 最小值
range() # 最大、小值
mean() # 均值
var() # 方差（variance）
sd() # 标准差（standard deviation）
prod() # 连乘的积
median() # 中位数
quantile(向量, 百分比combine) # 默认四分位数 eg. quantile(x, c(0.4,0.5))

# 索引值
which.max() # 向量中最大值的位置
which.min() # 向量中最小值的位置
which(向量==目标值) # 目标值在向量中的位置
which(向量>目标值) #大于目标值的数在向量中的位置
向量(which(向量>目标值)) # 大于目标值的数在向量中的数


#             2. 矩阵与数组（matrix）-------------------------------------------

# （多维的向量）
matrix(向量, nrow = 行数, ncol = 列数, byrow = T/F) # 制作一个矩阵
matrix(向量, 行数, 列数) # 可以直接写
# 向量中元素个数必须大于或等于matrix的格数（行数 x 列数 <= 元素数）
# Data length must be a sub-multiple or multiple of the number of rows
# byrow = T 时matrix先填行，再填列，反之亦然

dimnames(matrix) <- list(行名集, 列名集)
# 如何加行、列名

dim(向量) # 输出向量的维度，也可直接赋值来改变向量的维度
# > dim(x) # x <- c(1, 2)
#   NULL
# > dim(x) <- c(1, 2)  # 为向量x添加维数，可将向量变为矩阵
# >  x
#       [,1] [,2]
#   [1,]  1   2
# > dim(x) <- c(2,2,5) # 可添加多维，将向量变为多维数组

# 数组（更多维）
array(向量, 维数集, dimnames = 维度名的list)
# eg. array(1:6, c(1, 2, 3)指1行2列3层, dimnames = list(c("A1"), 
#                                                     c("B1", "B2"),  
#                                                     c("C1", "C2", "C3")))

# 矩阵索引
matrix[行数, 列数] # 列数和行数不一定只是一个数，可以是个集
matrix[行数] # 访问指定行数的第一列
matrix[行数,] # 访问指定行数的整行
matrix[,列数] # 访问指定列数的整列
matrix[-行数, 列数] # 访问除了指定行数的全部行数，而后访问指定列
matrix["行名", "列名"] # 如果matrix已有行、列名，也可直接用行、列名索引

# 矩阵运算
# 行列不一致的两个矩阵无法相加减
rowSums(matrix) # matrix每一行的和
colSums(matrix) # matrix每一列的和
rowMeans() # matrix每一行的平均数
colMeans() # matrix每一列的平均数
matrix1 * matrix2 # 内积
matrix1 %*% matrix2 # 外积
diag(matrix) # matrix的对角线值
t(matrix) # matrix的行列互换


#             3. 列表（list）---------------------------------------------------
# 列表是一些对象的有序集合，可以存储若干向量、矩阵、数据框，甚至其他列表的组合

# 制作列表
list(第一个对象,第二个对象, ...) 
list(第一对象名 = 第一个对象, 第二对象名 = 第二个对象, ...) 
# 为对象添加名称，后可通过名称直接访问对象
 
# 访问单个对象
列表名[对象位置]
列表名["对象名"] # 这里访问需要加引号

# 访问多个对象
列表名[c(对象1位置, 对象2位置, ...)]
列表名[c("对象1名", "对象2名", ...)] 
列表名$对象名 # 一般对象名会自动给

# ***mlist[1]和mlist[[1]]的区别***
mlist[1]
# 类型为list, 输出的为列表自身的内容
# 要删减列表可以使用单括号负索引，如：mlist[-2]等于去除第二个list
mlist[[1]]
# 输出的为列表对应内容的类型
# 类型为一开始组成列表的元素，如vector、matrix等（也可能是列表）
# 所以要改或加mlist里面的元素，需要两个括号
# 删减列表可以把list里面的元素赋值NULL，eg. mlist[[1]] <- NULL

# 删减都会造成所有的数据在列表中的位置变化

# ***单双中括号的区别***
# 把列表当作一列火车，单中括号相当于选择某节车厢，双中括号相当于选择某节车厢里的内容

#             4. 数据框（数据集）-----------------------------------------------
# 数据框是一种表格式的数据结构，数据框旨在模拟数据集。
# 数据集是由数据构成的一个巨型数组。

# - 行（row）表示观测（object）
# - 列（column）表示变量（dose）
#       col1  col2  col3
# row1
# row2
# row3

# 矩阵必须为同一数据类型
# 数据框每一列必须同一类型，但每一行可以不同。

?data.frame # 查看帮助文件
data.frame(变量1, 变量2, ...) # 制作数据框
# 将数据存储到R进行分析，只需将每个内容单独存储为一个向量，用data.frame合并即可

# 访问数据框
数据集[列/"列名"] # 可以用c()一步查看多列，会输出一个带行的新数据框
数据集["行名",] # 一行 + 全列
数据集[, "列名"] # 全行 + 一列
# 列/行前添加-，表示去掉该列/行
数据集$列名 # 全行 + 一列  
# 可使用该方式绘制散点图，eg. plot(数据集$列名1,数据集$列名1
# 可使用线性回归，eg. lm(列名1,列名2, data = 数据集)

with(数据集, {列名}) # 直接输出全列

attach(数据集) # 把数据集的列名导入R，之后可以直接访问
detach(数据集) # 消除数据集的列名


#             5. 因子（factor）-------------------------------------------------

# 变量类型：
#   - 名义型（nominal）：无顺序的/项目之间是独立的/比如名字
#   - 有序型（ordinal）：项目之间有关联但不是连续的数量变化/比如poor, better, best
#   - 连续型（continuous）：有顺序的/连续的数量变化/比如金额、增产率等

# 名义型（nominal）和有序型（ordinal）都属于因子
# 名义型（nominal）和有序型（ordinal）变量的可能值为水平(level)
# 水平值（level）构成的向量为因子
# 因子的作用：计算概率和频数、独立性检验、相关性检验、方差分析、主成分分析、因子分析...

# eg.
# > ?mtcars
# > mtcars$cyl
#   [1] 6 6 4 6 8 6 8 4 4 6 6 8 8 8 8 8 8 4 4 4 4 8 8 8 8 4 4 4 8 6 8 4
# > table(mtcars$cyl) # 计算频数  # mtcars$cyl作为因子
#    4  6  8  # 因子的水平值
#   11  7 14  # 频数

# factors      Lever 1     Level 2     Level 3
# * $ &
# * * *   ->    ****        $$          &&&
# $ & &

# 因子型数据
factor(c(数据集), orderred = T/F, levels = c("level1", "level2", ...))
# 会输出数据集和levels的顺序
# factor前一般需要赋值，eg. week <- factor(...)

# 将向量转化为因子
fcyl <- factory(mtcars$cyl)

# 绘图（因子输出条形图📊，向量输出散点图）

# 散点图
# ^ level
# | 
# |         ...
# |     ...
# | ...
# |
# ----------------> index

# 条形图
# ^ 数量
# | 
# |         ---
# |     --- | |
# | --- | | | |
# | | | | | | |
# ----------------> level

hist(MyMclust$uncertainty) # 绘制直方图（命令详见Cubox#hist)


# cut(被分割的向量, (把0到100, 总level数量为10, 等分10份))
cut(1:100, c(seq(0, 100, 10)))
cut(向量, c(seq(0, 100, 10)))

class(数据集) # eg. class(state.region) # 查找当前数据集的类别

#             6. 缺失数据-------------------------------------------------------

# - 测量值丢失
# - 没有值
# - 无效值

# NA表示缺失值（NA不一定等于零）
# > 1 + NA
#   NA
# > NA == 0
#   NA 

# 函数中关于缺失值的参数
na.rm = T/F # 是否移除缺失值（注：选了T后，函数计算相当于缺失值从未出现）
is.na(数据集) # 预先查询数据集中是否存在缺失值

# 消除向量中的NA
na.omit(原向量) # 如果是数据集使用na.omit()，会把有NA的整行都删除掉

# 其他缺失数据

# 插补缺失值
# 单个插补（简单）：Hmisc包
# 多重插补：Mi包, Mice包, amelia包, mitools包

NaN # 代表不可能的值（比如0/0），不存在的 
is.nan() # 查询是否为NaN

Inf # 代表正无穷（1/0）
-Inf # 代表负无穷（-1/0）
is.infinite() # 查询是否为无穷
!is.infinite() # 剔除数据集中为无穷的数

Na # 是存在的，但不知道是多少


#             7. 字符串（string/str）-------------------------------------------

# 要加引号！

正则表达式 

nchar() # 向量中每个元素（字符串）的长度
length() # 向量中元素的个数

paste() # 粘贴字符串，将多个字符串合并为一个
# > paste(c("a", "b", "c"))
#   "a" "b" "c" # 因为c()，三个向量不在一个维度，分别处理
# > paste("a", "b", "c")
#   "a b c" # 默认是空格分割
# > paste("a", "b", "c", sep="-")
#   "a-b-c" # sep为分割参数
# > f <- c("m","n","l")
# > paste(f,"a","b","c")
#   "m a b c" "n a b c" "l a b c"

substr(向量, start = 第一个字符, stop = 最后的字符) # 用于提取部分字符
# eg. substr(x = month.name, strat = 1,stop = 3)

toupper() # 全大写
tolower() # 全小写
sub # 只进行一次替换，将字母替换为首字母大写
gsub # 进行全局替换，将字母替换为首字母大写
# 使用正则化语言
gsub("^(\\w)","\\U\\1",tolower(字符型向量))
gsub("^(\\w)","\\U\\1",tolower(字符型向量),perl = T) # 首字母大写
gsub("^(\\w)","\\L\\1",tolower(字符型向量),perl = T) # 首字母小写

grep # 查找字符串
# > x <- c("b","A+","AC")
# > grep("A+",x) # 正则化语言中，+可代表1-正无穷个字符
#   2 3
# > grep("A+",x,fixed = T)
#   2
# > grep("A+",x,fixed = F)
#   2 3

match() # 查找包含于
# eg.
# > match("AC",x)
#   3

# 用于分割字符串，返回的是一个列表不是向量
strsplit(字符串向量/集, "分隔符") 
# > path <- "/usr/local/bin/p"
# > strsplit(path,"/")
#   ""      "usr"   "local" "bin"   "p"
# > path <- "usr/local/bin/p"
# > strsplit(path,"/")
#   "usr"   "local" "bin"   "p"

# 对向量1和向量2使用制定函数
outer(向量1, 向量2, FUN = 函数名)


#             8. 日期和时间（date）---------------------------------------------

# 对时间序列的描述
# 利用前面的结果进行预测

"ts" # time series 时间数据的简称
# ts不是数据框,data.frame是数据框，才可以用 $ 函数引用某列

Sys.Date() # 查看系统时间

# 将数字变为日期类
as.Date(向量, format = "%Y-%m-%d") # %y指直接年份，如20
# 例子
a <- "2020-01-01"
class(a) # "character"
class(as.Date(a)) # "Date"，日期类

?strftime # 时间函数相关介绍

# 创造连续时间点
seq(as.Date("2017-01-01"), as.Date("2017-07-05"), by=5)
# by参数为相隔天数（从起始开始，每隔by天出一个数）

# ?ts # 生成时间序列，可以将向量转化为时间函数
ts(data, 
   start = c(起始年, 起始年的第几个频率单位), 
   end = c(终止年, 终止年的第几个频率单位), 
   frequency = 频率数)
# Creating time-series objects
# frequency频率变化：
# 1 以年为单位
# 12 以月份为单位
# 4 以季度为单位
# 例子：

# > sales <- round(runif(48, min=50, max=100)) # round函数用于取整，runif生成随机数

# > sales
# [1] 56 75 75 85 51 73 63 79 73 88 57 81 72 85 58 60 87 77 55 86 65 71 50 91 64 63 59
# [28] 60 64 82 75 81 60 75 95 50 75 87 79 85 57 50 62 86 52 72 98 97

# > ts(sales, start = c(2010,5), end = c(2014,4), frequency = 1) 以年为单位
# Time Series:
# Start = 2014 
# End = 2017 
# Frequency = 1 
# [1] 56 75 75 85

# 因为frequency=1，所以起始为从2010开始算的第五年，即2014年。
# 结束为2014开始算的第四年，即2017年。
# 2014-2017，总4年，可以有四个数据指向时间。
# 因为可以fill的时间不够，多余的数据就被省略掉了。

# > ts(sales, start = c(2010,5), end = c(2014,4), frequency = 4) 以季度为单位
#       Qtr1 Qtr2 Qtr3 Qtr4
# 2011   56   75   75   85
# 2012   51   73   63   79
# 2013   73   88   57   81
# 2014   72   85   58   60

# 2010开始的第五季度，即2011第一季度；2014开始的第四季度，即2014第四季度。

# > ts(sales, start = c(2010,5), end = c(2014,4), frequency = 12) 以月份为单位
#       Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
# 2010                  56  75  75  85  51  73  63  79
# 2011  73  88  57  81  72  85  58  60  87  77  55  86
# 2012  65  71  50  91  64  63  59  60  64  82  75  81
# 2013  60  75  95  50  75  87  79  85  57  50  62  86
# 2014  52  72  98  97                                

 

# P28     获取数据--------------------------------------------------------------

# 1. 键盘输入

# Creating a dataframe
patientID <- c(1, 2, 3, 4)
admdate <- c("10/15/2009", "11/01/2009", "10/21/2009", "10/28/20009")
age <- c(25, 34, 28, 52)
diabetes <- c("Type1", "Type2", "Type1", "Type1")
status <- c("Poor", "Improved", "Excellent", "Poor")
data <- data.frame(patientID, admdate, age, diabetes, status) # 数据框
#   patientID     admdate age diabetes    status
# 1         1  10/15/2009  25    Type1      Poor
# 2         2  11/01/2009  34    Type2  Improved
# 3         3  10/21/2009  28    Type1 Excellent
# 4         4 10/28/20009  52    Type1      Poor
?edit # 可以调用允许手动输入文本的文字编辑器
data2 <- data.frame(patientID = character(0), 
                    age = numeric(0), 
                    diabetes = character(0), 
                    status = character(0)) 
data2 <- edit(data2) # 可视编辑器，必须赋值给原定义变量
fix(data2) # 可选择fix函数修改，可直接保存




# 2. 读取外部文件


# 3. 访问数据库

# ODBC = open database connectivity 开放数据库
install.packages("RODBC")
# 双向通信，读写和写入




# P29-30  读入文件--------------------------------------------------------------

?read.table()
x <- read.table("input.txt") # 默认空白分割 # 在当前工作目录下
x <- read.table("文件绝对路径/相对路径") # 文件不在当前工作路径下
# e.g. x <- read.table("/Users/nan-fan/Desktop/R软件学习/RData/input.txt")

x <- read.table("input.csv", sep=",", header = T, skip = 5, nrows = 100, 
                na.strings = " ") 
# sep设置分隔符，此为逗号分割，默认空白分割
# 第一行是否为变量名称
# skip的行数
# nrows：总共导入多少行
# 自动转化缺失值

head(x, n = 6) # 提取最开始的六行（默认六行）
tail(x, n = 6) # 提取最末尾的六行

read.csv() # 读取csv文件
read.fwf("fwf.txt",wudths = c(3,3)) # fixed width file, 需要设置宽度值

read.csv("路径\文件名",encoding="utf_8")
# fileEncoding:在声明文件上使用的编码(即重新编码字符数据)
# encoding:不用于重新编码输入,只是标记字符串为已知编码,允许R以本机编码处理编码字符串
# 注:读取文件时,也读取了字符编码集

x <- read.table("website", header = T)

install.packages("XML") # 网络读取数据的包
?readHTMLTable
# e.g.
# readHTMLTable("https:...",which=3) # which 表示选取第which个图表


install.packages("foreign") # 读取不同软件格式的数据的包
help(package = "foreign")
# 要读取的文件格式在foreign包中没有，可以进行网络搜索
RSiteSearch("Matlab")

# Excel直接复制到剪贴板导入
x <- read.table("clipboard", header = T, sep = "\t") # Windows
x <- read.table(pipe("pbpaste")) # Mac

read.table(gzfile("input.txt.gz")) # gz file

# 不规则格式文件的读取
?readLines  
readLines("input.csv", n = 5) # n = 返回行数

?scan # 读取文件之后，会根据指令进行处理
scan("input.txt", what = list(numeric(0)))
scan("input.txt", what = list(X1 = character(3),
                              X2 = numeric(0),
                              X3 = numeric(0)))
# 数字表示读入的数量，0表示所有
# 每一行读取3个字符串内容


# P31     写入文件--------------------------------------------------------------

?write # 直接写入文件，区别于read的读取文件
write.table(x, file = "x.txt") # 直接将文件写入table中
# e.g.
x <- read.table("input.txt",header = T)
write.table(x, file = "/Users/nan-fan/Desktop/R软件学习/x.txt")

write.table(x, file = "x.csv", sep = "\t", quote = F, append = F, 
            na = "NA", row.names = F)
# append = F清空源文件（T加在原文件后）
# na 默认缺失值，调整缺失值的字符
# row.names取消自动添加的行号

# 可直接写为压缩包
write.table(mtcars,gzfile("newfile.txt.gz"))
write.csv
write.csv(MyMclust$parameters$pro, "Mclust_proportions.csv", row.names = FALSE)


# P32     读写Excel文件---------------------------------------------------------

# Excel文件另存为csv格式
x <- read.csv("文件名.csv",header = T)

# 复制剪贴板
x <- read.table(pipe("pbpaste"))

# Excel的格式：.xlsx

# XLConnect包，需要JAVA环境
install.packages("XLConnect") # 需要rJava包
# 读取文件（两步法）
x <- loadWorkbook("data.xlsx") # 导入文档
edata <- readWorksheet(x, 1) # 读取文档 # 不同的工作表，数字为工作表编号
head(edata) # 查看数据，显示前6行
?readWorksheet
readWorksheet(x,1,startRow = 0,startCol = 0,endRow = 50,endCol = 3,header = T)
# 读取文档；读取文档中工作表编号；起始行；起始列；终止行；终止列；是否读取表头
# 读取文件（一步法）
readWorksheetFromFile("data.xlsx", 1)

# 写入（四步法）
y <- loadWorkbook("file.xlsx", create = T) # 创建工作簿/文件
createSheet(y, "Sheet 1") # 在工作簿中创建工作表
writeWorksheet(y, data = x, sheet = "Sheet 1") # 将数据保存到工作表中
saveWorkbook(y) # 将工作簿存为.xlsx文件
# 写入（一步法）
?writeWorksheetToFile
writeWorksheetToFile("file.xlsx", data = iris, sheet = "Sheet 1")

vignette("XLConnect") # 查看更多XLConnect的帮助文档

# xlsx包，需要JAVA环境
install.packages("xlsx")
library(xlsx)
help(package="xlsx")
# 读取文件
read.xlsx("data.xlsx", 1, startRow = 1, endRow = 100)
# 写入文件
write.xlsx(x, file = "rdata.xlsx", sheetName = "Sheet 1", append = T/F)
# 写入的数据；文件名；工作表名称；是否追加写入

# openxlsx包，不用JAVA环境


# P33     读写R格式文件---------------------------------------------------------

# .RDS -> R data set
?saveRDS
saveRDS(data, file = "data.RDS") # 储存为RDS文件至公共目录
x <- readRDS("data.RDS") # 读入RDS文件

# .R

# .RData 
load("data.RData") # 两个.RData文件中相同变量的数据会覆盖，因此最好提前了解文件内容
save(data1, data2, file = "data.RData") # 将两个数据集保存于同一个.RData文件
save.image() # 保存当前工作空间中的所有对象


# P34-40  数据格式转换----------------------------------------------------------

# 添加、删减、排序数据

# 数据框
library(xlsx)
setwd("/Users/nan-fan/Desktop/R软件学习/RData/")
cars32 <- read.xlsx("mtcars.xlsx",sheetIndex = 1,header = T) # 导入数据集
is.data.frame(data) # 用来判断数据类型
new.data <- as.data.frame(data) # 其他数据类型转换为数据框

# 数据框转为矩阵
data.frame(state.region,state.x77) # 在state.x77数据框中加入字符串state.region
as.matrix(data.frame(state.region,state.x77)) # 该矩阵变为字符串
# 可用method()查看is/as命令包含的全部内容
method(is)
method(as)
# 给向量添加一个维度，就变成矩阵/数组
x <- state.abb
dim(x) <- c(5,10)
as.factor(x) # x编程因子类型
as.list(x) # 由向量变为列表
state <- data.frame(x, state.region,state.x77) # 加上一个因子和矩阵就构成数据框
state$Income # 取出数据框中的列，为向量
state["Nevada",] # 取出一行，为数据框，并附带列名
is.data.frame(state["Nevada",]) # 判断是否为数据框
y <- state["Nevada",]
unname(y) # 去除列名
unlist(list) # 将其转化为向量

# 数据取子集
who <- read.csv("WHO.csv", header = T) # 导入数据
head(who)
who1 <- who[c(1:50), c(1:10)] # 连续提取 # 取前50行，10列（想要的那部分）
who2 <- who[c(1,3,5,8),c(2,14,16,18)] # 不连续提取
View(who2) # 浏览表格who2的内容
who$Continent # 使用列名
who2 <- who[which(who$Continent == 7)] # 使用which函数来定位（逻辑判断）# 等式判断
who3 <- who[which(who$CountryID > 50 & who$CountryID <= 100)] # 多重逻辑
?subset # 取子集
who4 <- subset(who, who$CountryID > 50 & who$CountryID <= 100) # data, logic
?sample # 随机提取部分数据
x <- 1:100
sample(x, n, replace = T/F) # n为输出数量，replace为是否可以重复，即是否可放回
sort(sample(x, n, replace = T/F)) # 对抽样结果进行排序
who[sample(who$CountryID, 30, replace = F),] # 随机抽取数据集CountryID 30个子集

# 删除固定行
data[-1:-5] # 负索引
data$row <- NULL # 赋值NULL # 相当于清空该列或行的数据

# 数据框合并->

# 合并列
data.frame(d1, d2) # 创造一个新的数据框
# data.frame(USArrests,state.division)
?cbind
cbind(d1, d2) # 在第一个数据框下改

# 合并行（d1和d2列名得相同）
?rbind
rbind(d1, d2)
# e.g.
data1 <- head(USArrests,20)
data2 <- tail(USArrests,20)
rbind(data1, data2)

# 矩阵也可以用cbind和rbind，必须有相同的行数或列数
rownames(data4) # 统计数据集的行名
length(rownames(data4)) # 统计数据集的行名个数，以检查是否有重复项
# 去除重复项 -> 取子集
duplicated(data)  # 判断向量或数据集中哪些是重复值
data[duplicated(data),] # 输出重复部分
data[!duplicated(data),] # 输出非重复部分
unique(data) # 直接去除重复数据

# 翻转数据框
# Excel转置选项
# R
new.data <- t(data) # 行列翻转
?rev
rev() # 用于向量/数据框
data[rev(rownames(data)),] # 单翻转行，比如1->10变成10->1
# e.g.
women # 数据集
rownames(women) #列出行名
rev(rownames(women)) # 对行名进行翻转
women[rev(rownames(women)),] # 列不变，对行进行翻转

# 修改数据库中的值
# 列运算
new.data <- data.frame(c1 = data$c1 * 2, c2 = data$c2) # 组成一个新的数据框
transform(data, c1 = c1 * 2) # 直接修改原数据
transform(data, c3 = c1 * 2) # 在原数据上加一列新数据

# 向量的排序->
?sort
sort(data) # 数字从小到大，字符从a到z（只能用于向量，不能用于数据框）
rev(sort(data)) # 按照相反方向排序
data[sort(rownames(data)),] # 用sort来排序数据框的方法（输出新数据框）

# 数据框的排序-> 通过对行和列分别排序，再通过索引达到共同排序
data[sort(rownames(data)),] # 展示出按照列排序后的数据集
# e.g. mtcars[sort(rownames(mtcars)),]
?order
order() # 返回索引值, 即向量元素在排序后所在的位置，而非最后结果
data[order(data$target),] # 按照target列从小到大排列
data[order(-data$target),] # 按照target列从大到小排列
data[order(data$t1, data$t2),] # 两个排序条件
# e.g.
mtcars$mpg
order(mtcars$mpg) # 返回向量元素在排序后所在的位置
mtcars[order(mtcars$mpg),] # 返回数据框mtcars按照mpg列从小到大排列后的结果
mtcars[order(-mtcars$mpg),] # 返回数据框mtcars按照mpg列从大到小排列后的结果

?rank
rank() # 求秩

# 数据框数学运算->
WorldPhones
wordphone <- as.data.frame(WorldPhones) # 将矩阵转化为数据框
rs <- rowSums(wordphone) # 计算数据框中每年总数，即求行和
cm <- colMeans(wordphone) # 计算数据框中每列平均数，即求列平均
total <- cbind(wordphone,Total=rs) # 将行总和添加到最后列，输出整个数据框
rbind(tatal,cm) # 将平均值添加到最后一行，但是会出现最后一行最后一列被重复计算
# 用apply系列函数解决最后重复问题



# for dataframe, matrix，数组
?apply
apply(data, MARGIN = 1, FUN = sum) # 行
apply(data, MARGIN = 2, FUN = mean) # 列
# e.g.
apply(WorldPhones, MARGIN = 1, FUN = sum) # 对行求和
apply(WorldPhones, MARGIN = 2, FUN = mean) # 对列求平均值
apply(WorldPhones, MARGIN = 2, FUN = var) # 对列求方差
apply(WorldPhones, MARGIN = 2, FUN = log) # 对列求对数

?lapply
lapply(list, FUN = length) # for list(列表)，返回集合中元素个数
sapply() # for vector, matrix，以向量形式返回集合中元素个数
tapply(data1, data2, FUN = length) # for factor
# e.g.
state.center # 列表
class(state.center) # 识别数据类型
lapply(state.center, FUN = length) # 返回每个集合中的值
class(lapply(state.center, FUN = length)) # 识别数据类型
sapply(state.center, FUN = length) # 以向量形式返回集合中元素个数
class(sapply(state.center, FUN = length)) # 识别数据类型

?tapply # 处理因子数据，根据因子进行分组，而后分组处理

# e.g.
state.name # 美国50个州名
state.division # 美国50个州的分区
tapply(state.name, state.division, FUN = length) # 统计每个大区包含州数量
# tapply中第二项最重要为因子分组依据

# apply系列函数->
# 该系列函数中最重要的是FUN,可以调用不同函数来处理问题

# 分组计算
tapply() # 参数：vector / 返回值：vector
apply() # 参数：list, data.frame, array / 返回值：vector, matrix

# 多参数计算
mapply() # 参数：vector，不限个数 / 返回值：vector, matrix

# 循环迭代
lapply() # 参数：list, data.frame / 返回值: list
# -简化版
sapply() # 参数：list, data.frame / 返回值：vector, matrix
# - - 可设置返回值
vapply() # 参数：list, data.frame / 返回值：vector, matrix
# -递归版
rapply() # 参数：list / 返回值：list

# 环境空间遍历
eapply() # 参数：environment / 返回值：list


# Centering and standardization 中心化与标准化->

# 中心化（方差）：data set中的各项数据减去data set的均值
# 标准化（标准差）：中心化之后在除以data set的标准差，即data set中的各项数据减去data set的均值再除以data set的标准差
# 使不同类型数据大小接近
# 先中心化，数据差还是大的话再标准化
# 中心化：
x - mean(x)
# 标准化：
(x - mean(x)) / sd(x) # sd() # 标准差

?scale
scale(x, center = T/F, scale = T/F)
# 参数center = T为中心化处理
# 参数scale = T为标准化处理
# x可直接设置为数据集名
head() # 处理完之后浏览处理结果
# e.g.
x <- scale(state.x77, center = T, scale = T) # 中心化和标准化处理
head(x) # 查看处理结果
head(state.x77) # 查看原数据集，可对比
heatmap(x) # 查看热图
# 中心化和标准化后，绘制heat map区别会更加明显


# reshape2包->
x <- data.frame(k1 = c(NA,NA,3,4,5), k2 = c(1,NA,NA,4,5), data = 1:5)
y <- data.frame(k1 = c(NA,2,NA,4,5), k2 = c(NA,NA,3,4,5), data = 1:5)
# cbind(x,y) rbind(x,y)，使用两者合并之后无法了解来自x或y的具体内容
?merge
merge(x, y, by = "k1")
merge(x, y, by = "k2")
merge(x, y, by = "k2", incomparables = T) # incomparables表示丢掉NA的情况
merge(x, y, by = c("k1", "k2"))

install.packages("reshape2")
library(reshape2)
help(package="reshape2")
?melt # 对宽数据进行处理，得到长数据
?dcast # 处理数据框 # 读取melt结果
?acast # 将长数据变为宽数据 # 返回向量/矩阵/数组

melt(data) # 可以把宽数据变成长数据，列名变为因子
melt(data, id.vars = ) # id.vars 是观测排序的参数

dcast(data, month+day ~variable) # 重铸数据，以month和day列为排序
# ～表示二者相关联，但并不一定相等
dcast(data, month ~ variable, fun.aggregate = sum, na.rm = T)
# 单以month为排列参数会有很多行有相同优先值
# 所以fun.aggregate的函数用来把有着相同month的数据运行一个设定的函数

# e.g.
airquality
head(airquality) # 列出行名（表头）
names(airquality) <- tolower(names(airquality)) # 将行名改为小写
head(airquality) # 在此查看表头
melt(airquality) # 把长数据变为宽数据,variable是因子类型
aql <- melt(airquality) # 赋值于aql
head(aql) # 查看aql
aql <- melt(airquality,id.vars = c("month","day")) # 添加id变量
# 要告诉melt函数，month和day是作为ID，其余4个作为变量值，ID是用于区分不同行数据的变量，
# 要告诉melt函数，数据中哪些作为行的观测，哪些作为列的观测值，
# 因此使用id.var，将month和day作为ID变量
head(aql,50)
aqw <- dcast(aql,month+day ~variable) # 对数据进行重铸
head(aqw)
aqw <- dcast(aql,month ~variable,fun.aggregate = mean,na.rm=TRUE)
# 在没有day之后，R不知道该如何处理相同month的值，
# fun.aggregate给定函数指定处理方式，e.g. sum mean var sd
# na.rm参数将存在的缺失值定义为TRUE
head(aqw)


# tidyr包（Tidy data）->

install.packages("tidyr")  # tidy data
library(tidyr)
help(package="tidyr") # 查看帮助文档
# 不能有两个相同行名和列名的unit

# e.g.
mtcars
tdata <- mtcars[1:10,1:3] # 选取部分数据
tdata <- data.frame(names=rownames(tdata),tdata) # 将原数据列名调入数据，同时原列名不变
tdata # 查看结果
gather(tdata,key = "Key", value = "Value",cyl,disp,mpg)
# 定义变量和值，对cyl、disp、mpg进行处理
gather(tdata,key = "Key", value = "Value",cyl:disp,mpg) # 将cyl和disp放于一列
gather(tdata,key = "Key", value = "Value",cyl,-mpg) # 排除mpg
gather(tdata,key = "Key", value = "Value",2:4) # 可直接写列的编号，2-4列

gdata <- gather(tdata,key = "Key", value = "Value",2:4)
gdata
spread(gdata,key = "Key", value = "Value") # 重新将数据集gdata变为tdata


# 宽变长
gather(data, key = "Key", value = "Value", factor1, factor2, facotr3)
# factor其实就是列，把每一列变成一种因子
gather(data, key = "Key", value = "Value", 2:4) # 可以直接输入列的编号

# 长变宽
spread(data, key = "Key", value = "Value") # gather的反函数
# 会自动把key里面不同的因子变为不同的列名

# 分隔与合并
df <- data.frame(x = c(NA, "a.b", "b.c", "a.d"))
separate(df, col = x, into = c("c1", "c2")) # 会自动识别分割符
df <- data.frame(x = c(NA, "a.b-c", "b-c", "a-d")) 
separate(df, col = x, into = c("c1", "c2"), sep="-") # 有多个分割符使需要标明
unite(x, col = "united col", c1, c2, sep="-")
# separate的反函数，把两列连起来，需表明连置符

# e.g. 
df <- data.frame(x = c(NA, "a.b", "b.c", "a.d"))
separate(df, col = x, into = c("A", "B")) # 会自动识别分割符
df <- data.frame(x = c(NA, "a.b-c", "b-c", "a-d"))
df
separate(df, col = x, into = c("A", "B"), sep="-") # 有多个分割符使需要标明
x <- separate(df, col = x, into = c("A", "B"), sep="-") # 赋值于x
x # 查看x
unite(x, col = "AB", A, B, sep="-") # 重新连起来，合并




# dplyr包->
install.packages("dplyr")
library(dplyr)
ls("package:dplyr")
help(package="dplyr")

dplyr::filter(data, c2 > 10) # filter掉不符合后面逻辑的行

dplyr::distinct(rbind(data[1:10,], data[1:15,])) # distinct去掉重复的十行

dplyr::slice(data, 10:15) # 取出制定行

dplyr::sample_n(data, n) # 随机取出n行
dplyr::sample_frac(data, 0.1) # 按几率取出行

dplyr::arrange(data, c2) # 按照某一列的大小来排序（从小到大）
dplyr::arrange(data, desc(c2)) # 按照某一列相反的大小来排序（从大到小）

?select
select() # 对数据框取子集

# e.g.
iris
dplyr::filter(iris,Sepal.Length>7) # 过滤花萼长度<7的数据，可选定特定行进行过滤
# 为避免dplyr中命令与其他包的命令重复，因此使用 dplyr::命令 来调用
dplyr::distinct(rbind(iris[1:10,],iris[1:15,])) # 选定1-10列，1-15行，去除重复
dplyr::slice(iris,10:15) # 选出特定行
dplyr::sample_n(iris,10) # 随机抽取10行
dplyr::sample_frac(iris,0.1) # 按比例随机选取
dplyr::arrange(iris, Sepal.Length) # 按照花萼长度进行排序
dplyr::arrange(iris, desc(Sepal.Length)) # 按照花萼长度进行逆向排序


# 统计函数
summarise(data, avg = mean(c2)) # 计算平均长度
summarise(data, sum = sum(c2)) # 计算总长度
# e.g.
summarise(iris,avg=mean(Sepal.Length)) # 计算花萼的平均长度
summarise(iris,avg=sum(Sepal.Length)) # 计算花萼的总长度

# 链式操作符 %>%（管道）
# 用于实现将一个函数的输出传递给下一个函数，作为下一个函数的输入。
# 快捷键：ctrl + shift + M
# 相当于“然后”
# 例子：
head(data, 20) # 取出data的前20行
head(data, 20) %>% tail(10)
# 先取出data的前二十行，再从这二十行里面取出最后的十行，所以最终输出为11-20行。

dplyr::group_by(data, c5) # 通过制定列的因子来进行分组，每一种因子为一组。
data %>% group_by(c5) # 另一种写法
data %>% group_by(c5) %>% summarise(avg = mean(c2)) %>% arrange((avg))
# 先分组，再算平均值，再排序
# e.g.
dplyr::group_by(iris, Species) # 通过Species对iris进行分组
iris %>% group_by(Species) # 通过管道分组，结果同上
iris %>% group_by(Species) %>% summarise() # 分组统计
iris %>% group_by(Species) %>% summarise(avg = mean(Sepal.Width)) # 分组之后计算均值
iris %>% group_by(Species) %>% summarise(avg = mean(Sepal.Width)) %>% arrange((avg))
# 先分组，再算平均值，再排序

dplyr::mutate(data, new=c2+c3) # 加新的一列，并添加逻辑

# 双表格整合

a <- data.frame(x1 = c("A","B","C"), x2 = c(1,2,3))
a
b <- data.frame(x1 = c("A","B","D"), x2 = c(T,F,T))
b
dplyr::left_join(a, b, by="x1") # x1以第一个数据框为准
#   x1 x2.x  x2.y
# 1  A    1  TRUE
# 2  B    2 FALSE
# 3  C    3    NA
dplyr::right_join(a, b, by="x1") # x1以第二个数据框为准
#   x1 x2.x  x2.y
# 1  A    1  TRUE
# 2  B    2 FALSE
# 3  D   NA  TRUE   # 因为a的x1没有D，所以x2.x是NA
dplyr::full_join(a, b, by="x1") # 全联接 # 把所有可能都列出来了
#   x1 x2.x  x2.y
# 1  A    1  TRUE
# 2  B    2 FALSE
# 3  C    3    NA
# 4  D   NA  TRUE
dplyr::semi_join(a, b, by="x1") # 半联接 # 根据右侧表内容对左侧表进行过滤，列出交集
#   x1 x2
# 1  A  1
# 2  B  2
dplyr::anti_join(a, b, by="x1") # 反联接 # 列出a，b的不同行
#   x1 x2
# 1  C  3

# 多个数据集的合并

intersect(data1, data2) # 取交集
dplyr::union_all(data1, data2) # 取并集
dplyr::union(data1, data2) # 取非冗余的并集
setdiff(data1, data2) # 取data1的补集

# e.g.
mtcars
first <- slice(mtcars,1:20) #取出mtcars数据集的前20行
# mtcars <- mutate(mtcars,Model=rownames(mtcars)) # 为数据集添加一列
second <- slice(mtcars,10:30)
first
second
intersect(first, second) # 取交集
dplyr::union_all(first, second) # 取并集
dplyr::union(first, second) # 取非冗余的并集
setdiff(first, second) # 取first的补集


# P41     R函数-----------------------------------------------------------------

# 例子：
state <- as.data.frame(state.x77[, c("Murder", "Population", "Illiteracy", "Income", "Frost")])
# 将state.x77转为数据框
class(state.x77)
class(state)
fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = state)
# 使用lm函数进行回归分析
summary(fit)

# 函数的返回值
# 一些有返回，一些没有

# 绘图函数输出图形，需要指定绘图设备，将结果输出指定设备中

# 向量
sum()
mean()
sd()
range()
median()
sort()
order()

# 矩阵或数据框
rbind()
cbind()

# 数字矩阵
heatmap()

# 可以使用help()来看不懂的函数


# P42     选项参数--------------------------------------------------------------

ls("package:base")
par()

# 规律

# 1. 输入控制部分
# 可以接收哪种类型的数据
# file：接一个文件
# data：一般指要输入一个数据框
# x：一个单独的对象，一般是向量，  但也可能是矩阵或者列表
# x和y：函数需要两个输入变量
# x, y, z：函数需要三个输入变量
# formula：公式
# na.rm：是否删除缺失值
# ...表示参数可传递，或没有数量限制
# ~ 表示相关

# 2. 输出控制部分

# 3. 调节部分
# （1）根据名字判断选项的作用：
# color选项：控制颜色
# select 与选择有关
# font 与字体有关
# font.axis 坐标轴的字体
# lty = line type # 线型
# lwd = line width # 线宽
# method 软件算法
# （2）选项接受哪些参数：
# main：字符串，不能是向量
# na.rm：TRUE or FALSE
# axis：side参数只能是1到4
# fig：包含四个元素的向量
# 不取值可能是NULL或者NA
# method参数与算法相关


# P43     数学统计函数----------------------------------------------------------

# 概率函数

# R概率分布
# d 概率密度函数（density）
# p 分布函数（distribution）
# q 分布函数的反函数（quantum？）
# r 产生相同分布的随机数（random）

# 正态分布
?Normal
dnorm()
pnorm()
qnorm()
rnorm()

# 离散分布

# 分布的作用
x <- rnorm(n=100, mean=15, sd=2) # 生成正态分布
qqnorm(x) # 生成正态分布图

?Geometric  # 几何分布
?Hypergeometric # 超几何分布

# 对分布进行检验

# 生产随机数
?runif
runif(n) # 生产n个0-1的随机数
runif(n, min = 1, max = 100) # min/max参数设置范围
round(runif(n, min = 1, max = 100)) # 使用round生成整数
dgamma(c(1:9),shape = 2,rate = 1) # 生成gamma分布的概率密度

# 随机数种子
set.seed(n) # 每次运行可以使之后的随机数相同，n为种子编码


# P44     描述性统计函数--------------------------------------------------------

# summary()提供向量的各项数据，比如最大小值、平均值、四分位数、因子频数向量统计等
myvars <- mtcars[c("mpg", "hp", "wt", "am")]
summary(myvars)

fivenum(myvars$hp)
# 返回五个数：最小值、四分位数第一、中位数、四分位数第三、最大值

# Descriptive stats via describe (Hmisc)
install.packages("Hmisc")
library(Hmisc)
myvars <- c("mpg", "hp", "wt")
describe(mtcars)
describe(mtcars[myvars])

# Descriptive stats via stat.desc (pastecs)
install.packages("pastecs")
library(pastecs)
stat.desc(myvars)
stat.desc(mtcars[myvars])
stat.desc(mtcars, basic = T, desc = T, norm = T)
# basic = T 计算基本值
# desc = T 计算描述值
# norm = T 计算统计值

# Descriptive stats via describe (psych) 
install.packages("psych")
library(psych)
describe(mtcars)
describe(mtcars[myvars], trim = 0.1)
# trim = 0.1 去除最低10%和最高10%的数据
?describe
Hmisc::describe(mtcars)
# 函数顺序：后入为主（后面载入的包函数会覆盖前面的包函数）
# 用::来表明函数来源

# Descriptive stats by group with aggregate
library(MASS)
aggregate() # 每次只能用一个统计函数
# e.g.
?Cars93
head(Cars93) # 数据第一列为字符型向量，无法计算要剔除
Cars93[c("Min.Price","Price","Max.Price","MPG.city")]
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
          by = list(Manufacturer=Cars93$Manufacturer),mean)
# 对每个汽车制造商产品价格进行统计
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
          by = list(Cars93$Origin),mean)
# 对是否为国产汽车进行价格统计
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
          by = list(Cars93$Origin),sd)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
          by = list(Cars93$Origin,Manufacturer=Cars93$Manufacturer),mean)
# 可以同时进行多个分组


# Descriptive stats by group via summaryBy
install.packages("doBy")
library(doBy)
?summaryBy
# 同时展示多个统计结果
summaryBy(mpg+hp+wt ~ am, data=mtcars, FUN=mystats)
# 不同变量之间用+，～右侧为类别型的分组变量，data指定参数集，FUN参数指定函数
summaryBy(mpg+hp+wt ~ am, data=mtcars, FUN=mean)

# Descriptive stats by group via describe.by (psych)
library(psych)
# 计算分组统计量
describeBy(mtcars[myvars], list(am=mtcars$am)) 
# 添加分组列表，给定list即可
# 给出的统计值是固定的，没办法使用自定义的函数
describeBy(mtcars, list(am=mtcars$am)) 


# P45     频数统计函数----------------------------------------------------------

# frequency table
mtcars
mtcars$cyl <- as.factor(mtcars$cyl) # 将mtcars$cyl该列转化为因子
split(mtcars, mtcars$cyl) # 按照因子进行分组
split(mtcars, as.factor(mtcars$cyl)) # 直接以cyl的因子分类

cut(mtcars$mpg, c(seq(10, 50, 10))) # 最后一个数为间隔数（10-20，20-30，30-40，40-50）

?table
table(mtcars$cyl) # 频数的统计,可直接加入因子
table(cut(mtcars$mpg, c(seq(10, 50, 10)))) # 可直接加入分割结果
prop.table(table(mtcars$cyl)) # 计算每种因子的比例

# 二维数据框
library(vcd)
table(Arthritis$Treatment, Arthritis$Improved) # 统计二者频率
with(data=Arthritis, table(Treatment, Improved))
? xtabs
x <- xtabs(~ Treatment + Improved, data = Arthritis)
# 表示根据Treatment + Improved两个参数进行计算，data选项为数据集

margin.table(x) # 统计x
margin.table(x, 1)
prop.table(x, 1) # 统计频率
addmargins(x) # 将编辑的和添加到频数表中
addmargins(x，1)
# 1 = 只添加行
# 2 = 只添加列


# 三维
y <- xtabs(~ Treatment + Improved + Sex, data = Arthritis)
y
ftable(y) # 平铺式的列联表



# P46     独立性检验函数--------------------------------------------------------

# 根据频数信息，判断两类因子，彼此相关或相互独立的假设检验
# 独立性：变量之间是独立的，没有关系

# p-value (probability)：在原假设为真时，得到最大的或者超出所得到的检验统计量值的概率。
# 原假设：没有发生 / 备择假设：发生了
# 一般将p值定位到0.05，当p<0.05拒绝原假设（不靠谱），当p>0.05不拒绝原假设（靠谱）。
# p值设定的越小，越精确。
# 计算出的p值越小越好

# 卡方检验（Chi-square test）
library(vcd)
mytable <- table(Arthritis$Treatment, Arthritis$Improved) # 变量的顺序不重要
?chisq.test # 进行卡方独立检验
chisq.test(mytable)

# Fisher's exact test
?fisher.test
mytable <- xtabs(~Treatment+Improved, data=Arthritis) 
fisher.test(mytable)

# Cochran-Mantel-Haenszel检验
?mantelhaen.test
mytable <- xtabs(~Treatment+Improved+Sex, data=Arthritis) # 变量的顺序很重要（因为要三个变量）
mytable
mantelhaen.test(mytable)


# P47     相关性分析函数--------------------------------------------------------

# 相关性分析：对两个或多个具备相关性的变量元素进行分析，从而衡量两个变量因素的相关密切程度。
# 相关性的元素之间需要存在一定的联系或者概率才可以进行相关性分析（变量之间是否有关系）

# 正相关或负相关（相关系数）
# Pearson相关系数
# Spearman相关系数
# Kendall相关系数
# 偏相关系数
# 多分格（polychoric）相关系数
# 多系列（polyserial）相关系数

# 使用cor()计算相关系数
?cor
state.x77
?cor(state.x77) # 默认method="pearson"
cor(state.x77, method="spearman")
# 正负号表示正相关或负相关
?cov
cov(state.x77) # 协方差

colnames(state.x77)
x <- state.x77[, c(1,2,3,6)]
y <- state.x77[, c(4,5)]
head(x)
head(y)
cor(x, y)

# partial correlations 偏相关系数
install.packages("ggm")
library(ggm)
# partial correlation of population(1) and murder rate(5), controlling 
# for income(2), illiteracy rate(3), and HS graduation rate(6)
colnames(state.x77)
pcor(c(1,5,2,3,6), cov(state.x77))


# P48     相关性检验函数--------------------------------------------------------

# Testing a correlation coefficient for significance
?cor.test
cor.test(state.x77[,3], state.x77[,5])

# Confidence interval（置信区间）
# 样本统计量所构造的总体参数的估计区间（被测量参数的测量值的可信程度）
# 概率发生的范围
# 展现的是这个参数的真实值有一定概率落在测量结果的周围的程度。

# Correlation matrix and tests of significance via corr.test
corr.test(states, use="complete")
library(psych)
corr.test(state.x77) # 不仅给出相关系数，而且给出检测值
library(ggm)
?pcor.test
x <- pcor(c(1,5,2,3,6), cov(state.x77))
pcor.test(x, 3, 50) # 3 -> 变量数，50 -> 样本数
# 分别输出：学会说呢给的t检验、自由度、p-value


# Two Sample  t-test
library(MASS)
?t.test
UScrime
?UScrime
t.test(Prob ~ So, data=UScrime)
t.test(y ~ x, data = )

# 非参数检验（Nonparametric test）：在总体方差未知或知道甚少的情况下，利用样本对总体分布形态等进行推断的方法。
# 参数检验（Parametric test）:总体分布形式已知的情况下，对总体分布的参数（如均值、方差等）进行推断的方法。也就是数据分布已知，比如满足正态分布。

# dependent t test
sapply(UScrime[c("U1", "U2")], function(x)(c(mean=mean(x), sd=sd(x))))
with(UScrime, t.test(U1, U2, paired=T))



# P49     绘图函数--------------------------------------------------------------

# 1. R基础绘图系统
ls("package:graphics")
demo(graphics) # 展示出R中能绘制的图
help(package=graphics)
# （1）高级绘图：一步到位，直接绘制出图
# （2）低级绘图：不能单独使用，得在高级绘图产生图形的基础上，对图形进行调整，比如加线、标题文字等
# 知道输入数据的格式很重要：
# 散点图：x和y两个坐标数据
# 直方图📊：因子
# 热力图：数据矩阵
plot(women$height)
plot(women$height, women$weight)
plot(as.factor(women$height)) # 绘制直方图

plot(as.factor(mtcars$cyl)) # 直方图
plot(mtcars$cyl) # 散点图
plot(as.factor(mtcars$cyl), mtcars$carb) # 箱线图
plot(mtcars$carb, as.factor(mtcars$cyl)) # 散列图
plot(as.factor(mtcars$cyl), as.factor(mtcars$carb)) # 脊柱图

plot(women$height ~ women$weight) # 另一种写法

fit <-lm(height ~ weight, data=women)
plot(fit) # plot会自动检测输入的数据类型来进行不同的绘图


# S3系统（面向对象）：属性，泛型函数，方法
methods(plot) # 查看plot的内容
methods(print)
methods(summary)

?par # parameter（用于微调）
par() # 显示R绘图的默认设置
plot(as.factor(mtcars$cyl), col=c("red", "green", "blue")) # col为其中一项参数

# 2. lattice包

# 3. ggplot2包

# 4. grid包


# P50     自定义函数------------------------------------------------------------

# 自己编写函数
# 输入不加括号的函数，输出源代码

# 1. 函数名称
# 1.1 函数命令与功能相关
# 1.2 可以是字母与数字的结合，但必须是字母开头
# 2. 函数声明
# 3. 函数参数
# 4. 函数体

myfun <- function(选项参数)
{
  函数体
        }

# 例子：计算偏度和峰度的函数
# 偏度（skewness）：统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。
# 峰度（peakedness；kurtosis）：峰态系数。表征概率密度分布曲线在平均值处峰值高低的特征数。
x <- 1:100
mystats <- function(x, na.omit=FALSE) {
  if(na.omit)
    x <- x[!is.na(x)] # x只取不包含NA的值
  m <- mean(x)
  n <- length(x)
  s <- sd(x)
  skew <- sum((x-m)^3 / s^3) / n
  kurt <- sum((x-m)^4 / s^4) / n-3
  return(c(n=n, mean=m, stdev=s, skewness=skew, kurtosis=kurt))
}
mystats(x)

# 循环与向量化操作：函数内部通过循环实现向量化操作
# if条件判断
score=70;if (score > 60) {print("Passed")} else {print("Failed")}
ifelse(score > 60, "Passed", "Failed") # 两种写法（ifelse自带输出功能）
# for循环
for (i in 1:10) {print("Hello")}
# while循环
i=1;while(i <= 10) {print("Hello");i=i+1;}
# switch语句等

# 循环三部分
# 1. 条件判断，真或假
# 2. 用于循环执行的结构
# 3. 表达式

rawData$ratio1 <- (rawData$act + rawData$dlc) / (rawData$act + rawData$ppent)
# 数据集列的计算方法

# P51     数据分析实战----------------------------------------------------------

# 小麦产量案例
# 房地产案例
# 性价比案例
# 药物试验案例
# 社会科学研究案例
# 量化投资案例（计量经济学）

# 反面案例
# 苹果的Think different？？？


# P52-53  线性回归（regression）------------------------------------------------

# 回归：指那些用一个或多个预测变量（自变量、解释变量），来预测响应变量（因变量、效标变量、结果变量）的方法。
# 根据一大堆数据，找到它们的规律。

# 如何建立模型。抽象出数学公式，哪些因素与模型有关，需要利用多少样品，模型的准确率有多高，在实际运用中还是否有效。

# 线性回归 或 非线性回归

# 普通最小二乘回归法（OLS）
women
plot(women$height, women$weight)
?lm
fit <- lm(formula = weight ~ height, data = women) # 线性回归分析（拟合）
fit
summary(fit) 
# 残差（residuals）越小，越接近线性关系
# R-squared 表示符合模型的数据占比
# 一般先看p-value是否<0.05，如果不小于一般说明模型不符合
# 再看R-squared，有多少数据符合模型

"~" #分割符号
# 左边为响应变量（y），右边是解释变量（x）。
# 例如，要通过x、z和w预测y，代码为y~x+z+w

"+" # 分隔预测

":" # 表示预测变量的交互项
# 比如，要通过x、z及x与z的交互项来预测y，代码为y ~ x + z + x:z

"*" # 表示所有可能交互项的简洁方式
# 代码 y ~ x * z * w 可展开为 y ~ x + z + w + x:z + x:w + z:w + x:z:w

"^" # 表示交互项达到某个次数
# 代码 y ~ (x + z + w)^2 可展开为 y ~ x + z + w + x:z + x:w + z:w

"." # 表示包含除因变量外的所有变量
# 比如，若一个数据框包含变量x、y、z和w，代码 y ~. 可展开为 y ~ x + z + w

"-" # 减号，表示从等式中移除某个变量
# 代码 y ~ (x + z + w)^2 - x:w 可展开为 y ~ x + z + w + x:z + z:w

"-1" # 删除截距项
# 比如，表达式 y ~ x - 1 拟合y在x上的回归，并强制直线通过原点

I() # 从算术的角度来解释括号中的元素
# 比如，y~x+(z+w)^2 展开为 y~x+z+w+z:w
# 代码 y~x+ I((z+w)^2) 展开为 y~x+h （h是一个由z和w的平方和创建的新变量）

"function()" # 可以在表达式中用的数学函数
# 比如，log(y) ~ x + z + w 表示通过x、z和w来预测log(y)

# 线性拟合常用函数
summary() # 展示拟合模型的详细结果
coefficients() # 列出拟合模型的模型参数（y-intercept和slope）
confint(data, level = 0.5) # 提供模型参数的confidence interval（默认95%，用level参数调整）
fitted() # 列出拟合模型的预测值
residuals() # 列出拟合模型的残差值（残差（residuals）越小，越接近线性关系）
anova() # 生成一个拟合模型的方差分析表，或者比较两个或多个拟合模型的方差分析表
vcov() # 列出模型参数的协方差矩阵
AIC() # 输出赤池信息统计量
plot() # 生成评价拟合模型的诊断图
predict(model, new.data) # 用拟合模型对新的数据集预测响应变量值
abline() # 绘制拟合曲线，直线

# e.g.
coefficients(fit)
confint(fit)
confint(fit, level = 0.5)
fitted(fit) 
women$weight-fitted(fit)
residuals(fit)
women1 <- women # 新生成数据
predict(fit,women1) # 对新生成的数据预测
plot(fit)
plot(women$height,women$weight)
abline(fit) # 绘制拟合直线

# 多项式
fit2 <- lm(weight ~ height + I(height^2), data = women) # 回归式中平方的写法
fit2
summary(fit2)
lines(women$height, fitted(fit2), col="red") # 结果显示带有二次项的函数可以更好拟合
lines(x, y) # 横坐标（x），纵坐标（y）（这里纵坐标用了预测值）
#三次项
fit3 <- lm(weight ~ height + I(height^2) + I(height^3), data = women)
summary(fit3)
lines(women$height, fitted(fit3), col="blue")

# 不能拟合不足，也不能拟合过度



# P54     多元线性回归----------------------------------------------------------

# 多个变量，权重也不同
state.x77
states <- as.data.frame(state.x77, c("Murder", "Population", "Illiteracy", "Income", "Frost"))
# 转化为数据框
fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
summary(fit)
coef(fit)
options(digits = 4) # 显示小数点后4位
# qqplot(fit, labels = row.names(states), id.method = "identify", simulate = T, main = "Q-Q Plot")

fit2 <- lm(mpg ~ hp + wt + hp:wt, data = mtcars)
summary(fit2)

# 如何从众多模型中，选择最佳模型
?AIC
# 比较模型,AIC值越小越好
m1 <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
m2 <- lm(Murder ~ Population + Illiteracy, data = states)
AIC(m1, m2)

# 逐步回归法（Backward stepwise selection）
library(MASS)
states <- as.data.frame(state.x77, c("Murder", "Population", "Illiteracy", "Income", "Frost"))
fit <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
stepAIC(fit, direction = "backward")

# 全子集回归法（All subsets regression）
library(leaps)
states <- as.data.frame(state.x77, c("Murder", "Population", "Illiteracy", "Income", "Frost"))
leaps <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbest = 4)
plot(leaps, scale = "adjr2")


# P55     回归诊断--------------------------------------------------------------

fit <-  lm(weight ~ height, data=women)
opar <- par(no.readonly = T)
par(mfrow=c(2,2)) # 表示横排竖排各显示两幅
plot(fit) # plot绘制出的四幅图是为了评价是否满足OLS模型统计假设四条件
# 图一 残差与拟合，因变量与自变量是否呈线性关系，图中点为残差值分布，曲线为拟合曲线。
#      若存在曲线，说明因变量与自变量存在二次方关系。
# 图二 Q-Q图，描述正态性，若数据呈正态分布，则点呈一条直线，残差值也成直线分布
# 图三 Scale-Location 位置与尺寸图，用来描述同方差性，若满足不变方差假设，曲线周围点呈随机分布
# 图四 Residuals vs Leverage 残差与杠杆图，提供对单个数据集的观测，从图中可鉴别偏差较远点，
#      从而分辨离群点、高杠杆点、强影响点。离群点表示该点残差值较大，不适合模型；
#      高杠杆点表示该点为异常预测变量组合；强影响点表示该点对模型参数的影响过大
#      这些点可用库克距离Cook's distance来鉴别，将这些点删除会使模型拟合更好；
#      或者对数据进行转换，如：对所有数据取指数、取对数等
par(opar)

# 满足OLS模型统计假设
# 1. 正态性：对于固定的自变量值，因变量值成正态分布
# 2. 独立性：因变量之间互相独立
# 3. 线性：因变量与自变量之间为线性关系
# 4. 同方差性：因变量的方差不随自变量的水平不同而变化。也可称作不变方差。

fit2 <- lm(weight ~ height + I(height^2), data = women)
opar <- par(no.readonly = T)
par(mfrow=c(2,2))
plot(fit2)
par(opar)

# 抽样法验证
# 1. 数据中有1000个样本，随机抽取500个数据进行回归分析
# 2. 模型建好后，利用predict()，对剩下的500个样本进行预测，比较残差值
# 3. 如果预测准确，说明模型可以，否则就需要调整模型



# P56-57  方差分析（Analysis of Variance）--------------------------------------------------------------

# 方差分析（Analysis of Variance / ANOVA），也称变异数分析
# 用于两个及两个以上样本均数差别的显著性检验。
# 从广义上来讲，方差分析属于回归分析的一种。但线性回归的因变量一般是连续型变量。而当自变量是因子时，研究关注的重点通常会从预测转向不同组之间差异的比较。

# 1. 单因素方差分析ANOVA（组内，组间）
y ~ A # 单因素ANOVA
y ~ A + Error(Subject/A) # 单因素组内ANOVA
y ~ B * W + Error(Subject/w) # 含单个组内因子（w）和单个组间因子（b）的重度测量ANOVA
# 案例
library(multcomp)
?cholesterol
attach(cholesterol) # 加载数据集
table(trt) # 进行分组统计，并展示
aggregate(response, by=list(trt), FUN=mean)
fit <- aov(response ~ trt, data = cholesterol) # 做方差分析
summary(fit) # 显示统计结果
plot(fit) # 对结果进行绘图
fit.lm <- lm(response ~ trt, data = cholesterol) # 定义新的变量
summary(fit.lm) # 展示回归结果
# 比较二者差别，线性拟合要求预测变量为数值型，lm函数在遇到变量为因子时，
# 就会用一系列与因子对照的数值型变量替换因子，因此lm也可以做方差分析

# 单因素协方差例子
litter # 示例数据集
?litter
table(litter$dose) # 统计分组情况
attach(litter) # 加载数据集
aggregate(weight,by=list(dose),FUN=mean) # 利用aggregate函数统计评卷值
fit <- aov(weight ~ gesttime+dose,data = litter) # 进行方差分析
summary(fit) # 显示统计结果

# 2. 双因素方差分析ANOVA
y ~ A * B
# 案例
ToothGrowth
?ToothGrowth
attach(ToothGrowth) # 加载数据集
xtabs(~ supp+dose) #统计频率
aggregate(len, by=list(supp, dose), FUN=mean) # 统计平均值
aggregate(len, by=list(supp, dose), FUN=sd)
ToothGrowth$dose <- factor(ToothGrowth$dose) # 将数据转化为因子
fit <- aov(len ~ supp*dose, data=ToothGrowth) # 进行supp和dose两个变量的方差分析
summary(fit)
install.packages("HH")  
library(HH)
interaction.plot(dose, supp, len, type = "b", col = c("red", "blue"), 
                 pch = c(16,18), 
                 main = "Interaction between Dose and Supplement Type")
# 对结果进行可视化，而且对任何因子涉及的主效应和交互效应都进行展示

# 3. 协方差分析ANCOVA
y ~ x + A # 含单个协变量的单因素ANCOVA
y ~ x1 + x2 + A*B # 含两个协变量的双因素ANCOVA
# 单因素协方差案例
table(litter$dose)
attach(litter) # 加载数据集
aggregate(weight, by=list(dose), FUN=mean)
fit <- aov(weight ~ gesttime+dose, data=litter) # gesttime为协变量
summary(fit)

# 4. 多元方差分析MANOVA
# 案例
library(MASS)
?UScereal
UScereal
attach(UScereal) # 加载数据集
shelf <- factor(shelf) # 将数据转化为因子
aggregate(cbind(calories, fat, sugars), by=list(shelf), FUN=mean) # 计算平均值，通过list进行分组
fit <- manova(cbind(calories, fat, sugars) ~ shelf, data=UScereal) # 检测不同组之间差别是否显著
# 由于自变量为calories, fat, sugars有三个，而因变量为shelf只有一个，左多右少，因此自变量之间不能用+，选择用cbind( , , )
summary(fit) # 查看结果
summary.aov(fit) # 查看更为详细结果

# 5. 多元协方差分析MANCOVA

?aov

y ~ B + A (B是区组因子) # 随机化区组

# 顺序很重要
y ~ A + B + A:B
# 在R中，顺序为序贯型。效应根据表达式中先出现的效应做调整。
# A不做调整，B根据A做调整，A:B交互项根据A和B调整。



# P58     功效分析（Power Analysis）--------------------------------------------

# 功效分析，可以帮助在给定置信度的情况下，判断检测到给定效应值时所需的样本量。
# 反过来，它也可以在给定置信度水平情况下，计算在某样本量内能检测到给定效应值的概率。

# 功效分析函数（pwr包中的函数）
install.packages("pwr")
library(pwr)
pwr.2p.test() # 两比例（n相等）
pwr.2p2n.test() # 两比例（n不相等）
pwr.anova.test() # 平衡的单因素ANOVA
pwr.anova.test(k=2, f=0.25, sig.level=0.05, power=0.90)
pwr.chisq.test() # 卡方检验
pwr.f2.test() # 广义线性模型（Linear Models）
pwr.f2.test(u=3, f2=0.0769, sig.level=0.05, power=0.90)
#  v = 184.2
# 假定显著性水平为0.05，在90%的置信度下，至少需要185个受治者才可以

# 方差分析功效分析案例
options(digits = 5)
pwr.f2.test(u=3, f2=0.0769, sig.level=0.05, power=0.90)

pwr.p.test() # 比例（单样本）
pwr.r.test() # 相关系数
pwr.t.test() # t检验（单样本、两样本、配对）
pwr.t.test(d=.8, sig.level=.05, power=.9, type="two.sample", alternative="two.sided")
pwr.t.test(n=20, d=.5, sig.level=.01, type="two.sample", alternative="two.sided")
pwr.t2n.test() # t检验（n不相等的两样本）

# 功效分析理论基础
# 1. 样本大小：实验设计中每种条件/组中观测的数目。
# 2. 显著性水平（alpha）：由I型错误的概率来定义，也可以把它看作是发现效应不发生的概率。
# 3. 功效：通过I减去II型错误的概率来定义，可以把它看作是真实效应发生的概率。
# 4. 效应值：指的是在备择或研究假设下效应的量。效应值的表达式依赖于假设检验中使用的统计方法。
# 有其中三个，就可以求出第四个数


# P59     广义线性模型----------------------------------------------------------

# 广义线性模型扩展了线性模型的框架，它包含了非正态因变量的分析。

?glm # Generalized Linear Models
install.packages("robust")
library(robust)
??breslow.dat
breslow.dat
data(breslow.dat, package="robust") # 加载数据集
names(breslow.dat) # 查看行名
summary(breslow.dat[c(6,7,8,10)]) # 统计数据集

# 泊松回归（Poisson regression）
# 用来为计数资料和列联表建模的一种回归分析。
# 假设因变量是泊松分布，并假设它平均值的对数可被未知参数的线性组合建模。

attach(breslow.dat)
# fit regression
fit <- glm(sumY ~ Base + Age + Trt, data = breslow.dat, family = poisson(link="log"))
# 注意泊松回归写法
summary(fit)

# intercept model parameter
coef(fit) # 获取模型系数
# 泊松回归中，因变量以条件变量的对数形式来建模，
# 保持其他自变量不变，自变量age增加1，因变量的对数均值将增加0.02274。
exp(coef(fit)) # 由于对数均值不方便分析，可以取指数
# 保持其他自变量不变，自变量age增加1，因变量将增加1.023。



# P60     Logistic回归----------------------------------------------------------

# 通过一系列连续型或类别型预测变量，来预测二值型结果变量时，Logistics回归很有用。
install.packages("AER")
library(AER)
?Affairs
Affairs
data(Affairs, package="AER")
summary(Affairs) # 对数据进行统计
table(Affairs$affairs) # 对数据进行分组
prop.table(table(Affairs$affairs)) # 按照次数进行频率分组
prop.table(table(Affairs$gender)) # 按照性别进行频率分组

# Logistic回归需要变量为二值型，可以创造
# create binary outcome variable
Affairs$ynaffairs[Affairs$affairs > 0] <- 1 # 令数据集中对应列的>0的数=1
Affairs$ynaffairs[Affairs$affairs == 0] <- 0 # 令数据集中对应列的=0的数=0
head(Affairs)
Affairs$ynaffairs <- factor(Affairs$ynaffair, levels = c(0,1), labels = c("No", "Yes"))
# 将Affairs$ynaffair变量转化为因子
head(Affairs)
table(Affairs$ynaffair) # 查看二值型变量分组结果

# fit full model
attach(Affairs) # 加载数据，可在输入变量时自动补齐
fit <- glm(ynaffairs ~ gender + age + yearsmarried + children + 
             religiousness + education + occupation + rating, 
           data = Affairs, family = binomial())
summary(fit)

# fit reduced model # 剔除不显著变量再拟合
fit2 <- glm(ynaffairs ~ age + yearsmarried + religiousness + rating, 
            data = Affairs, family = binomial())
summary(fit2)

# compare models
anova(fit, fit2, test = "Chisq") # 卡方检验值进行检验
coef(fit2) # 可用于比较两次模型模拟的差别，由于Pr(>Chi)=0.21，两次拟合结果相差不大，说明可以剔除不显著变量
exp(coef(fit2))

# calculate probability of extramarital affair by marital ratings
# predict 可以根据已有的数据结果fit2对模型新数据集进行验证
# 首先创造一个包含预测变量值的虚拟变量数据集testdata，此处为方便取数据平均值
testdata <- data.frame(rating = c(1,2,3,4,5), 
                       age = mean(Affairs$age), 
                       yearsmarried = mean(Affairs$yearsmarried), 
                       religiousness = mean(Affairs$religiousness))
testdata$prob <- predict(fit2, newdata = testdata, type = "response")
# 使用测试数据集预测相应概率
testdata # 查看数据集

# calculate probability of extramarital affair by age
# 控制其他变量，观察年龄变化出现婚外情的概率
testdata <- data.frame(rating = mean(Affairs$rating), 
                       age = seq(17, 57, 10), 
                       yearsmarried = mean(Affairs$yearsmarried), 
                       religiousness = mean(Affairs$religiousness))
testdata$prob <- predict(fit2, newdata = testdata, type = "response")
testdata
# 该方法可研究每一预测变量对结果的影响


# P61     主成分分析------------------------------------------------------------

# 主成分分析（Principal Component Analysis / PCA）
# 一种数据降维技巧。
# 它能将大量相关变量转化为一组很少的不相关变量，这些无关的变量称为主成分。
# 主成分其实是对原始变量重新进行线性组合，将原来众多具有一定相关性的指标，重新组合为一组的新的相互独立的综合指标。

# 主成分分析公式
# PC1 = A1X1 + A2X2 + ... + AkXk

# 主成分分析与因子分析步骤
# 1. 数据预处理
# 2. 选择分析模型
# 3. 判断要选择的主成分/因子数目（可通过碎石图）
# 4. 选择主成分/因子
# 5. 旋转主成分/因子
# 6. 解释结果（Optional）
# 7. 计算主成分/因子得分（Optional）

# Principal components analysis of the Judge Ratings
?princomp
library(psych)
help(package="psych")
USJudgeRatings
fa.parallel(USJudgeRatings, fa="pc", n.iter=100) # 碎石图（找出n.factors）
# 其中fa="pc"指做pc分析
# 其中n.iter=100指循环100次
# 可研究平行分析法
pc <- principal(USJudgeRatings, nfactors=1,rotate = "none",scores=FALSE)
# 通过principal函数定义（数据集，主成分个数，指定旋转方法，是否计算主成分得分
pc
# pc1表示观测变量与主成分的相关系数
# h2表示成分共因子的方差，主成分对每个变量的方差解释度
# u2指每个方差无法被主成分解释的比例
# SS loadings表示与该主成分相关联的特征值，与主成分相关联的变量标准化后的方差值
# Proportion Var表示该主成分对数据集的解释程度

# PCA Score
pc <- principal(USJudgeRatings, nfactors=1, rotate = "none",scores=T) # score为是否需要计算主成分得分，默认F
pc$scores

# PCA Harman23.cor data
Harman23.cor
fa.parallel(Harman23.cor$cov, n.obs=302, fa="pc", n.iter=100, show.legend=F, main="Scree plot with parallel analysis")
# 首先判断主成分的数目，填入目标数据集相关系数矩阵，n.obs设定样本大小，fa绘制碎石图，n.iter循环次数，
# PCA of body measurement
pc <- principal(Harman23.cor$cov, nfactors=2, rotate="none")
pc

# 使成分不相关：正交旋转（去噪）
# 使成分相关：旋交旋转
?principal
pc <- principal(Harman23.cor$cov, nfactors=2, rotate="varimax")
pc
# 旋转之后改变的只是主成分对方差的解释度，其解释度趋同，可称之为成分，而非主成分




# P62     因子分析--------------------------------------------------------------

# 探索性因子分析法（Exploratory Factor Analysis / EFA）
# 一系列用来发现一组变量的潜在结构的方法。
# 它通过寻找一组更小的、潜在的或隐藏的结构来解释已观测到的、显式的变量间的关系。
# 公共因子可解释多个变量之间的方差，因子分析就是为找到公共因子

# 因子分析公式
# Xi = A1F1 + A2F2 + ... + ApFp + Ui
# Xi：第i个可观测的变量
# F：公共因子
# Ui：Xi变量无法被公共因子解释的部分（误差）

# 主成分与因子分析比较

# 相同点
# 1. 都对原始数据进行降维处理
# 2. 都消除了原始指标的相关性对综合评价所造成的信息重复的影响
# 3. 构造综合评价时所涉及的权数具有客观性
# 4. 在信息损失不大的前提下，减少了评价工作量
# 5. 用碎石图来判断主成分/因子数量

# 不同点

# 主成分分析：
# 1. 用较少的变量表示原来的样本
# 2. 目的是样本数据信息损失最小的原则下，对高维变量进行降维
# 3. 参数估计，一般是求相关矩阵的特征值和相应的特征向量，取前几个计算主成分
# 4. 应用：应用较少变量来解释各个样本的特征

# 因子分析：
# 1. 用较少的因子表示原来的变量
# 2. 目的是尽可能保存原变量的相互关系，寻找变量的公共因子
# 3. 参数估计，指定几个因子，将其还原成相关系数矩阵，在和原样本相关矩阵最相似原则下，估计各个公因子的估计值
# 4. 应用：找到具有本质意义的少量因子来归纳原来变量的特征

?factanal()
library(psych)
ability.cov  # 查看数据集
options(digits = 2) # 保留两位小数
covariances <- ability.cov$cov # 由于ability.cov为列表，因此取出其中cov矩阵定义为covariances
correlations <- cov2cor(covariances) # 将协方差矩阵转换成系数矩阵
fa.parallel(correlations, fa="both", n.obs=112, n.iter=100) # 判断提取的因子数
?fa
fa <- fa(correlations, nfactors=2, rotate="none", fm="pa")
# fm定义提取公因子的方法，pa为主轴迭代法
fa
# 正交旋转（PC1和PC2没有关系）
fa.varimax <- fa(correlations, nfactors=2, rotate="varimax", fm="pa")
fa.varimax
# 斜交旋转（PC1和PC2有关系）
fa.promax <- fa(correlations, nfactors=2, rotate="promax", fm="pa")
fa.promax

# 正交和斜交的区别
# 对正交旋转，因子分析重点在因子结构矩阵
# 对斜交旋转，因子分析会考虑三个矩阵：因子结构矩阵、因子模式矩阵、因子关联矩阵
#             因子模式矩阵：即标准化后的回归系数矩阵，列出因子预测变量的权重
#             因子关联矩阵：即因子相关系数矩阵

# 绘制正交或斜交图形
factor.plot(fa.promax, labels = rownames(fa.promax$loadings))
fa.diagrams(fa.varimax, simple = F)
fa <- fa(correlations, nfactors=2, rotate="none", fm="pa", score = T)
fa$weights # 得分权重

install.packages("GPArotation")
library(GPArotation)

# P63     购物篮分析------------------------------------------------------------

# 数据加载
install.packages("arules")
library(arules)
data(Groceries)
inspect(Groceries) # 查看数据集内容

fit <- apriori(Groceries, parameter = list(support=0.01, confidence=0.5))
summary(fit)
inspect(fit)
# lift指数越大，逻辑可能性越大



# P64-65  后记------------------------------------------------------------------

# 白嫖不易，各自珍惜。

# 希望世界和平。

###---在R中调用MATLAB
#安装R.matlab包
install.packages("R.matlab")
#载入R.matlab包
library(R.matlab)

#设置matlab文件的路径
path<-system.file("mat-files",package="R.matlab")

#读取matlab文件
mat<-readMat(file.path(path,"structLooped.mat"))

#对读取内容（存放在mat变量中）进行操作（mat变量）
s<-mat$s
fields<-dimnames(S)[[1]]
cat("Field names:",paste(fields,collapse=","),"\n",sep=" ")
print(s)

